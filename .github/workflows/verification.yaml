name: Action Verification Test

on:
  # Run after the main build workflow completes
  workflow_run:
    workflows: ["Version and Release"]
    types:
      - completed
    branches:
      - main
  # Also allow manual triggering for testing
  workflow_dispatch:

jobs:
  verify-action:
    name: Verify Action Works as Expected
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      # We don't need to build again - release.yaml already does this
      # We just need to ensure we have the built files from dist/
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist
          path: dist/
        continue-on-error: true  # Continue even if there are no artifacts (like in manual runs)

      # Create test files
      - name: Create Test Files
        run: |
          mkdir -p test-files
          
          # Create base Python file
          cat > test-files/base.py << 'EOF'
          from pydantic import BaseModel
          from typing import List, Optional, Dict

          class Address(BaseModel):
              street: str
              city: str
              zipcode: str

          class User(BaseModel):
              id: int
              name: str
              email: str
              addresses: List[Address] = []
          EOF
          
          # Create new Python file with changes
          cat > test-files/new.py << 'EOF'
          from pydantic import BaseModel
          from typing import List, Optional, Dict, Any

          class Address(BaseModel):
              street: str
              city: str
              zipcode: str
              country: Optional[str] = None

          class User(BaseModel):
              id: int
              name: str
              email: str
              addresses: List[Address] = []
              age: Optional[int] = None
              metadata: Dict[str, Any] = {}
          EOF
          
          # Create current TypeScript file
          cat > test-files/current.ts << 'EOF'
          export interface Address {
            street: string;
            city: string;
            zipcode: string;
          }

          export interface User {
            id: number;
            name: string;
            email: string;
            addresses?: Address[];
          }
          EOF
          
          # Create output directory
          mkdir -p test-files/output

      # Execute the action directly using local code
      - name: Test Local Action
        run: |
          echo "Testing action by executing it directly..."
          # Print the version of node
          node --version
          # Run with additional debug logging
          NODE_DEBUG=anthropic,langchain,langsmith node dist/index.js
        env:
          INPUT_BASE-PYTHON-FILE: test-files/base.py
          INPUT_NEW-PYTHON-FILE: test-files/new.py
          INPUT_CURRENT-TYPESCRIPT-FILE: test-files/current.ts
          INPUT_OUTPUT-TYPESCRIPT-FILE: test-files/output/updated.ts
          INPUT_MODEL-PROVIDER: ${{ vars.MODEL_PROVIDER || 'anthropic' }}
          # Try using a different model that might not have the same streaming requirements
          INPUT_MODEL-NAME: ${{ vars.MODEL_NAME || 'claude-3-7-sonnet-latest' }}
          INPUT_ANTHROPIC-API-KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          INPUT_OPENAI-API-KEY: ${{ secrets.OPENAI_API_KEY }}
          INPUT_TEMPERATURE: 0.1
          # Optional LangSmith tracing
          # INPUT_LANGSMITH-API-KEY: ${{ secrets.LANGSMITH_API_KEY }}
          # INPUT_LANGSMITH-PROJECT: "action-verification"
          INPUT_VERBOSE: "true"

      # Verify the output looks correct
      - name: Verify Output
        run: |
          echo "Checking if output file was created..."
          if [ ! -f "test-files/output/updated.ts" ]; then
            echo "Error: Output file was not created"
            exit 1
          fi
          
          echo "Verifying output file content..."
          cat test-files/output/updated.ts
          
          # Check for expected content
          if ! grep -q "country?: string" test-files/output/updated.ts; then
            echo "Error: Output file does not contain expected field 'country?: string'"
            exit 1
          fi
          
          if ! grep -q "age?: number" test-files/output/updated.ts; then
            echo "Error: Output file does not contain expected field 'age?: number'"
            exit 1
          fi
          
          if ! grep -q "metadata?: Record<string, any>" test-files/output/updated.ts; then
            echo "Error: Output file does not contain expected field 'metadata?: Record<string, any>'"
            exit 1
          fi
          
          echo "âœ… Verification successful: Output contains expected changes"

      # Now test the action as it would be used in a workflow (optional if using repo secrets would be a problem)
      - name: Test Action as Workflow (Optional)
        if: false # Disable this step by default, enable if full workflow testing is needed
        uses: ./
        with:
          base-python-file: test-files/base.py
          new-python-file: test-files/new.py
          current-typescript-file: test-files/current.ts
          output-typescript-file: test-files/output/updated-workflow.ts
          model-provider: ${{ vars.MODEL_PROVIDER || 'anthropic' }}
          model-name: ${{ vars.MODEL_NAME || 'claude-3-7-sonnet-latest' }}
          anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}
          openai-api-key: ${{ secrets.OPENAI_API_KEY }}
          temperature: 0.1
          # Optional LangSmith tracing
          # langsmith-api-key: ${{ secrets.LANGSMITH_API_KEY }}
          # langsmith-project: "action-verification"
          verbose: "true"